{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-08-10 08:03:39.146799: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-10 08:03:39.207889: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-08-10 08:03:39.208915: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-08-10 08:03:40.158630: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import preprocessing\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input, Embedding, Dense, Dropout, Conv1D, GlobalMaxPool1D, concatenate\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                              query    intent  label\n",
      "0  아침도 아니고 밤 12시 30분에 결제한 건데도 그런가요?  주문_취소_확인      7\n",
      "1             실수로 취소하면 재주문해야 하는 거죠?  주문_취소_확인      7\n",
      "2                     택배비 따로 추가되나요?  배송_비용_질문      5\n",
      "3                          택배비 있나요?  배송_비용_질문      5\n",
      "4                        택배비 따로 들어요  배송_비용_질문      5\n",
      "len of queries =  235867\n",
      "len of intents =  235867\n"
     ]
    }
   ],
   "source": [
    "filename='intents_labeled_by_9'\n",
    "\n",
    "train_file = f'/home/azureuser/projects/aerius/ai/myapp/chatbot/datas/{filename}.csv'\n",
    "data = pd.read_csv(train_file, delimiter = ',')\n",
    "queries = data['query'].tolist()\n",
    "intents = data['label'].tolist()\n",
    "\n",
    "print(data.head(5))\n",
    "print('len of queries = ', len(queries))\n",
    "print('len of intents = ', len(intents))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The number of unique labels is 9\n"
     ]
    }
   ],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(intents)\n",
    "\n",
    "encoded_intents = encoder.transform(intents)\n",
    "num_classes = len(encoder.classes_)\n",
    "print(f\"The number of unique labels is {num_classes}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "from ai.myapp.chatbot.utils.Preprocess import Preprocess\n",
    "p = Preprocess()\n",
    "\n",
    "words = []\n",
    "for sentence in queries:\n",
    "    if isinstance(sentence, str):  # Only process if the sentence is a string\n",
    "        preprocessed = p.delete_intent_trash_tags(sentence=sentence)\n",
    "        word_list, _ = p.divide_words_tags(preprocessed)\n",
    "        words.extend(word_list)\n",
    "    else:\n",
    "        print(f\"Found non-string value: {sentence}\")\n",
    "\n",
    "\n",
    "# Initialize the tokenizer\n",
    "p.initialize_tokenizer(words)\n",
    "\n",
    "# Convert the queries into sequences\n",
    "sequences = []\n",
    "for sentence in queries:\n",
    "    sequence = p.text_to_sequence(sentence)\n",
    "    sequences.append(sequence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    File \"/home/azureuser/projects/aerius/venv/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/azureuser/projects/aerius/venv/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/azureuser/projects/aerius/venv/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/azureuser/projects/aerius/venv/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/azureuser/projects/aerius/venv/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"/home/azureuser/projects/aerius/venv/lib/python3.8/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/azureuser/projects/aerius/venv/lib/python3.8/site-packages/keras/src/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/azureuser/projects/aerius/venv/lib/python3.8/site-packages/keras/src/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/azureuser/projects/aerius/venv/lib/python3.8/site-packages/keras/src/losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/azureuser/projects/aerius/venv/lib/python3.8/site-packages/keras/src/backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None,) and (None, 10, 9) are incompatible\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[6], line 32\u001b[0m\n\u001b[1;32m     29\u001b[0m model\u001b[39m.\u001b[39mcompile(loss\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mcategorical_crossentropy\u001b[39m\u001b[39m'\u001b[39m, optimizer\u001b[39m=\u001b[39mtf\u001b[39m.\u001b[39mkeras\u001b[39m.\u001b[39moptimizers\u001b[39m.\u001b[39mAdam(\u001b[39m0.01\u001b[39m), metrics\u001b[39m=\u001b[39m[\u001b[39m'\u001b[39m\u001b[39maccuracy\u001b[39m\u001b[39m'\u001b[39m])\n\u001b[1;32m     31\u001b[0m \u001b[39m# 모델 학습\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_ds, validation_data\u001b[39m=\u001b[39;49mval_ds, epochs\u001b[39m=\u001b[39;49m\u001b[39m10\u001b[39;49m)\n\u001b[1;32m     34\u001b[0m \u001b[39m# 모델 평가\u001b[39;00m\n\u001b[1;32m     35\u001b[0m loss, accuracy \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mevaluate(test_ds)\n",
      "File \u001b[0;32m~/projects/aerius/venv/lib/python3.8/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m/tmp/__autograph_generated_file06nhhzg1.py:15\u001b[0m, in \u001b[0;36mouter_factory.<locals>.inner_factory.<locals>.tf__train_function\u001b[0;34m(iterator)\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     14\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m---> 15\u001b[0m     retval_ \u001b[39m=\u001b[39m ag__\u001b[39m.\u001b[39mconverted_call(ag__\u001b[39m.\u001b[39mld(step_function), (ag__\u001b[39m.\u001b[39mld(\u001b[39mself\u001b[39m), ag__\u001b[39m.\u001b[39mld(iterator)), \u001b[39mNone\u001b[39;00m, fscope)\n\u001b[1;32m     16\u001b[0m \u001b[39mexcept\u001b[39;00m:\n\u001b[1;32m     17\u001b[0m     do_return \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    File \"/home/azureuser/projects/aerius/venv/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1338, in train_function  *\n        return step_function(self, iterator)\n    File \"/home/azureuser/projects/aerius/venv/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1322, in step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    File \"/home/azureuser/projects/aerius/venv/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1303, in run_step  **\n        outputs = model.train_step(data)\n    File \"/home/azureuser/projects/aerius/venv/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1081, in train_step\n        loss = self.compute_loss(x, y, y_pred, sample_weight)\n    File \"/home/azureuser/projects/aerius/venv/lib/python3.8/site-packages/keras/src/engine/training.py\", line 1139, in compute_loss\n        return self.compiled_loss(\n    File \"/home/azureuser/projects/aerius/venv/lib/python3.8/site-packages/keras/src/engine/compile_utils.py\", line 265, in __call__\n        loss_value = loss_obj(y_t, y_p, sample_weight=sw)\n    File \"/home/azureuser/projects/aerius/venv/lib/python3.8/site-packages/keras/src/losses.py\", line 142, in __call__\n        losses = call_fn(y_true, y_pred)\n    File \"/home/azureuser/projects/aerius/venv/lib/python3.8/site-packages/keras/src/losses.py\", line 268, in call  **\n        return ag_fn(y_true, y_pred, **self._fn_kwargs)\n    File \"/home/azureuser/projects/aerius/venv/lib/python3.8/site-packages/keras/src/losses.py\", line 2122, in categorical_crossentropy\n        return backend.categorical_crossentropy(\n    File \"/home/azureuser/projects/aerius/venv/lib/python3.8/site-packages/keras/src/backend.py\", line 5560, in categorical_crossentropy\n        target.shape.assert_is_compatible_with(output.shape)\n\n    ValueError: Shapes (None,) and (None, 10, 9) are incompatible\n"
     ]
    }
   ],
   "source": [
    "from ai.backend.settings import INTENT_MAX_SEQ_LEN\n",
    "padded_seqs = preprocessing.sequence.pad_sequences(sequences, maxlen=INTENT_MAX_SEQ_LEN, padding='post')\n",
    "\n",
    "ds = tf.data.Dataset.from_tensor_slices((padded_seqs, encoded_intents))\n",
    "ds = ds.shuffle(len(queries))\n",
    "\n",
    "train_size = int(len(padded_seqs)*0.7)\n",
    "val_size = int(len(padded_seqs)*0.2)\n",
    "test_size = int(len(padded_seqs)*0.1)\n",
    "\n",
    "train_ds = ds.take(train_size).batch(20)\n",
    "val_ds = ds.skip(train_size).take(val_size).batch(20)\n",
    "test_ds = ds.skip(train_size + val_size).take(test_size).batch(20)\n",
    "\n",
    "vocab_size = len(p.tokenizer.word_index) + 1  # 단어 사전의 크기\n",
    "embedding_dim = 30  # 임베딩 벡터의 차원\n",
    "lstm_units = 200  # LSTM 레이어의 유닛 수\n",
    "output_classes = len(set(encoded_intents))  # 고유한 인텐트 레이블의 수\n",
    "max_len = INTENT_MAX_SEQ_LEN\n",
    "\n",
    "# 모델 구축\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_len, mask_zero=True),\n",
    "    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(lstm_units, dropout=0.50, recurrent_dropout=0.25)),\n",
    "    tf.keras.layers.Dense(output_classes, activation='softmax')\n",
    "])\n",
    "\n",
    "# 모델 컴파일\n",
    "model.compile(loss='categorical_crossentropy', optimizer=tf.keras.optimizers.Adam(0.01), metrics=['accuracy'])\n",
    "\n",
    "# one-hot 인코딩된 레이블을 사용하여 학습\n",
    "y_train_onehot = tf.keras.utils.to_categorical(np.concatenate([y for _, y in train_ds], axis=0), num_classes=output_classes)\n",
    "y_val_onehot = tf.keras.utils.to_categorical(np.concatenate([y for _, y in val_ds], axis=0), num_classes=output_classes)\n",
    "\n",
    "train_ds_onehot = tf.data.Dataset.from_tensor_slices((np.concatenate([x for x, _ in train_ds], axis=0), y_train_onehot)).batch(20)\n",
    "val_ds_onehot = tf.data.Dataset.from_tensor_slices((np.concatenate([x for x, _ in val_ds], axis=0), y_val_onehot)).batch(20)\n",
    "\n",
    "history = model.fit(train_ds_onehot, validation_data=val_ds_onehot, epochs=10)\n",
    "loss, accuracy = model.evaluate(test_ds)\n",
    "print(\"Test accuracy: {:.2f}%\".format(accuracy * 100))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1180/1180 [==============================] - 17s 10ms/step\n",
      "Precision: 0.1633\n",
      "Recall: 0.1834\n",
      "F1 Score: 0.1655\n",
      "Accuracy: 0.1834\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score, recall_score, f1_score, accuracy_score\n",
    "\n",
    "# 1. 모델 예측\n",
    "y_pred = model.predict(test_ds)\n",
    "y_pred_classes = np.argmax(y_pred, axis=1)\n",
    "\n",
    "# test_ds_resampled에서 라벨만 추출\n",
    "y_true = np.concatenate([y for x, y in test_ds], axis=0)\n",
    "\n",
    "# 2. 성능 지표 계산\n",
    "precision = precision_score(y_true, y_pred_classes, average='weighted', zero_division=1)\n",
    "recall = recall_score(y_true, y_pred_classes, average='weighted')\n",
    "f1 = f1_score(y_true, y_pred_classes, average='weighted')\n",
    "accuracy = accuracy_score(y_true, y_pred_classes)\n",
    "\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 1.2062445878982544\n",
      "Test accuracy: 0.5604596138000488\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds, verbose=0)\n",
    "\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1180/1180 [==============================] - 13s 10ms/step - loss: 1.2050 - accuracy: 0.5607\n",
      "Accuracy: 56.06715679168701\n",
      "loss: 1.2050210237503052\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/azureuser/projects/aerius/venv/lib/python3.8/site-packages/keras/src/engine/training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "loss, accuracy = model.evaluate(test_ds, verbose=1)\n",
    "print(f'Accuracy: {accuracy * 100}')\n",
    "print(f'loss: {loss}')\n",
    "\n",
    "model.save(f'/home/azureuser/projects/aerius/ai/myapp/chatbot/models/{filename}.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
